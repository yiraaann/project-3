


# Import Dependencies
import pandas as pd
import requests
import numpy as np
import os
import csv
from pathlib import Path



# Import Data from CSV files and Generate Dataframe
data_2012 = Path("../project-3/data/2012.csv")
data_2015 = Path("../project-3/data/2015.csv")
data_2016 = Path("../project-3/data/2016.csv")
data_2017 = Path("../project-3/data/2017.csv")
data_2018 = Path("../project-3/data/2018.csv")
data_2019 = Path("../project-3/data/2019.csv")
data_2020 = Path("../project-3/data/2020.csv")
data_2021 = Path("../project-3/data/2021.csv")
data_2022 = Path("../project-3/data/2022.csv")
data_2023 = Path("../project-3/data/2023.csv")
data_2024 = Path("../project-3/data/2024.csv")

df_2012 = pd.read_csv(data_2012, encoding="utf-8", low_memory=False, sep=",")
df_2015 = pd.read_csv(data_2015, encoding="utf-8", low_memory=False, sep=",")
df_2016 = pd.read_csv(data_2016, encoding="utf-8", low_memory=False, sep=",")
df_2017 = pd.read_csv(data_2017, encoding="utf-8", low_memory=False, sep=",")
df_2018 = pd.read_csv(data_2018, encoding="utf-8", low_memory=False, sep=",")
df_2019 = pd.read_csv(data_2019, encoding="utf-8", low_memory=False, sep=",")
df_2020 = pd.read_csv(data_2020, encoding="utf-8", low_memory=False, sep=",")
df_2021 = pd.read_csv(data_2021, encoding="utf-8", low_memory=False, sep=",")
df_2022 = pd.read_csv(data_2022, encoding="utf-8", low_memory=False, sep=",")
df_2023 = pd.read_csv(data_2023, encoding="utf-8", low_memory=False, sep=",")
df_2024 = pd.read_csv(data_2024, encoding="utf-8", low_memory=False, sep=",")



# Import Data from PDF file and Generate Dataframe - 2013 DATA
data_2013 = tabula.read_pdf("../project-3/data/2013.pdf", pages="1-6", pandas_options={'header':None}) 

df_2013_page1 = data_2013[0]
df_2013_page2 = data_2013[1]
df_2013_page3 = data_2013[2]
df_2013_page4 = data_2013[3]
df_2013_page5 = data_2013[4]
df_2013_page6 = data_2013[5]





# Import Data from CSV files and Generate Dataframe
data_coordinates = Path("../project-3/data/coordinates.csv")

df_coordinates = pd.read_csv(data_coordinates, encoding="utf-8", low_memory=False)


# Inspect Shape - Row/Column Count
df_coordinates.shape


# Inspect Column Headers
df_coordinates.columns


# Inspect Dataframe
df_coordinates.head()


# Create New Dataframe with Specific Headers - Renaming Columns
df_coordinates_new = df_coordinates[['latitude', 'longitude', 'name']]
df_coordinates_new = df_coordinates_new.rename(columns = {'latitude': 'Latitude', 'longitude': 'Longitude', 'name': 'Country'})
df_coordinates_new.head()


# Create CSV File
df_coordinates_new.to_csv('coordinates.csv', index=False, header=True)





# Inspect Shape - Row/Column Count
df_2012.shape


# Inspect Column Headers
df_2012.columns


# Inspect Dataframe
df_2012.head()


# Inspect Dataframe for Null Values
df_2012.isna().sum()


# Create New Dataframe with Specific Headers - Renaming Columns
df_2012_new = df_2012[['Country', 'Life Satisfaction']]
df_2012_new = df_2012_new.rename(columns = {'Country': 'Country', 'Life Satisfaction': 'Happiness Score - 2012'})
df_2012_new.head()





# Examine Dataframe Page 1
df_2013_page1.head()


# Remove the first row
df_2013_page1 = df_2013_page1.iloc[1:]
df_2013_page1.head()


# Set the first row as the header
df_2013_page1.columns = df_2013_page1.iloc[0]

# Drop the first row from the dataframe
df_2013_page1 = df_2013_page1[1:].reset_index(drop=True)
df_2013_page1.head()


# Inspect Column Headers
df_2013_page1.columns


# Create New Dataframe with Specific Headers - Renaming Columns
df_2013_page1_new = df_2013_page1[['Country', 'Ladder']]
df_2013_page1_new = df_2013_page1_new.rename(columns = {'Country': 'Country', 'Ladder': 'Happiness Score - 2013'})
df_2013_page1_new.head()


# Examine Dataframe Page 2
df_2013_page2.head()


df_2013_page2.columns


# Create New Dataframe with Specific Headers - Renaming Columns
df_2013_page2_new = df_2013_page2[[0, 2]]
df_2013_page2_new = df_2013_page2_new.rename(columns = {0: 'Country', 2: 'Happiness Score - 2013'})
df_2013_page2_new.head()


# Examine Dataframe Page 3
df_2013_page3.head()


# Create New Dataframe with Specific Headers - Renaming Columns
df_2013_page3_new = df_2013_page3[[0, 2]]
df_2013_page3_new = df_2013_page3_new.rename(columns = {0: 'Country', 2: 'Happiness Score - 2013'})
df_2013_page3_new.head()


# Examine Dataframe Page 4
df_2013_page4.head()


# Create New Dataframe with Specific Headers - Renaming Columns
df_2013_page4_new = df_2013_page4[[0, 2]]
df_2013_page4_new = df_2013_page4_new.rename(columns = {0: 'Country', 2: 'Happiness Score - 2013'})
df_2013_page4_new.head()


# Examine Dataframe Page 5
df_2013_page5.head()


# Create New Dataframe with Specific Headers - Renaming Columns
df_2013_page5_new = df_2013_page5[[0, 2]]
df_2013_page5_new = df_2013_page5_new.rename(columns = {0: 'Country', 2: 'Happiness Score - 2013'})
df_2013_page5_new.head()


# Examine Dataframe Page 6 
df_2013_page6.head(10)


# Remove any rows beyond Zimbabwe
df_2013_page6_shortened = df_2013_page6.iloc[:8]
df_2013_page6_shortened


# Use Regex to remove numbers from the 'Column 0'
df_2013_page6_shortened.iloc[:, 0] = df_2013_page6_shortened.iloc[:, 0].str.replace(r'\d+', '', regex=True).str.strip()

# Display the modified DataFrame
df_2013_page6_shortened


# Create New Dataframe with Specific Headers - Renaming Columns
df_2013_page6_shortened_new = df_2013_page6_shortened[[0, 2]]
df_2013_page6_shortened_new = df_2013_page6_shortened_new.rename(columns = {0: 'Country', 2: 'Happiness Score - 2013'})
df_2013_page6_shortened_new.head()


# Merge all dataframes into one
combined_df_2013 = pd.concat([df_2013_page1_new, df_2013_page2_new, df_2013_page3_new, \
                              df_2013_page4_new, df_2013_page5_new, df_2013_page6_shortened_new], ignore_index=True)

combined_df_2013


# Inspect Shape - Row/Column Count
combined_df_2013.shape


# Inspect Dataframe for Null Values
combined_df_2013.isna().sum()





# Inspect Shape - Row/Column Count
df_2015.shape


# Inspect Column Headers
df_2015.columns


# Inspect Dataframe
df_2015.head()


# Inspect Dataframe for Null Values
df_2015.isna().sum()


# Calculate the average of 'femladder' and 'menladder' and create a new column 'Average Ladder'
df_2015['Average Ladder'] = (df_2015['femladder'] + df_2015['menladder']) / 2
df_2015.head()


# Create New Dataframe with Specific Headers - Renaming Columns
df_2015_new = df_2015[['countrynew', 'Average Ladder']]
df_2015_new = df_2015_new.rename(columns = {'countrynew': 'Country', 'Average Ladder': 'Happiness Score - 2015'})
df_2015_new.head()





# Inspect Shape - Row/Column Count
df_2016.shape


# Inspect Column Headers
df_2016.columns


# Inspect Dataframe
df_2016.head()


# Inspect Dataframe for Null Values
df_2016.isna().sum()


# Create New Dataframe with Specific Headers - Renaming Columns
df_2016_new = df_2016[['Country', 'Happiness score']]
df_2016_new = df_2016_new.rename(columns = {'Country': 'Country', 'Happiness score': 'Happiness Score - 2016'})
df_2016_new.head()





# Inspect Shape - Row/Column Count
df_2017.shape


# Inspect Column Headers
df_2017.columns


# Inspect Dataframe
df_2017.head()


# Inspect Dataframe for Null Values
df_2017.isna().sum()


# Create New Dataframe with Specific Headers - Renaming Columns
df_2017_new = df_2017[['Country', 'Happiness score']]
df_2017_new = df_2017_new.rename(columns = {'Country': 'Country', 'Happiness score': 'Happiness Score - 2017'})
df_2017_new.head()





# Inspect Shape - Row/Column Count
df_2018.shape


# Inspect Column Headers
df_2018.columns


# Inspect Dataframe
df_2018.head()


# Inspect Dataframe for Null Values
df_2018.isna().sum()


# Create New Dataframe with Specific Headers - Renaming Columns
df_2018_new = df_2018[['Country', 'Happiness score']]
df_2018_new = df_2018_new.rename(columns = {'Country': 'Country', 'Happiness score': 'Happiness Score - 2018'})
df_2018_new.head()





# Inspect Shape - Row/Column Count
df_2019.shape


# Inspect Column Headers
df_2019.columns


# Inspect Dataframe
df_2019.head()


# Inspect Dataframe for Null Values
df_2019.isna().sum()


# Create New Dataframe with Specific Headers - Renaming Columns
df_2019_new = df_2019[['Country', 'Happiness score']]
df_2019_new = df_2019_new.rename(columns = {'Country': 'Country', 'Happiness score': 'Happiness Score - 2019'})
df_2019_new.head()





# Inspect Shape - Row/Column Count
df_2020.shape


# Inspect Column Headers
df_2020.columns


# Inspect Dataframe
df_2020.head()


# Inspect Dataframe for Null Values
df_2020.isna().sum()


# Create New Dataframe with Specific Headers - Renaming Columns
df_2020_new = df_2020[['Country name', 'Ladder score']]
df_2020_new = df_2020_new.rename(columns = {'Country name': 'Country', 'Ladder score': 'Happiness Score - 2020'})
df_2020_new.head()





# Inspect Shape - Row/Column Count
df_2021.shape


# Inspect Column Headers
df_2021.columns


# Inspect Dataframe
df_2021.head()


# Inspect Dataframe for Null Values
df_2021.isna().sum()


# Create New Dataframe with Specific Headers - Renaming Columns
df_2021_new = df_2021[['Country name', 'Ladder score']]
df_2021_new = df_2021_new.rename(columns = {'Country name': 'Country', 'Ladder score': 'Happiness Score - 2021'})
df_2021_new.head()





# Inspect Shape - Row/Column Count
df_2022.shape


# Inspect Column Headers
df_2022.columns


# Inspect Dataframe
df_2022.head()


# Inspect Dataframe for Null Values
df_2022.isna().sum()


# Create New Dataframe with Specific Headers - Renaming Columns
df_2022_new = df_2022[['Country', 'Happiness score']]
df_2022_new = df_2022_new.rename(columns = {'Country': 'Country', 'Happiness score': 'Happiness Score - 2022'})
df_2022_new.head()





# Inspect Shape - Row/Column Count
df_2023.shape


# Inspect Column Headers
df_2023.columns


# Inspect Dataframe
df_2023.head()


# Inspect Dataframe for Null Values
df_2023.isna().sum()


# Create New Dataframe with Specific Headers - Renaming Columns
df_2023_new = df_2023[['Country name', 'Ladder score']]
df_2023_new = df_2023_new.rename(columns = {'Country name': 'Country', 'Ladder score': 'Happiness Score - 2023'})
df_2023_new.head()





# Inspect Shape - Row/Column Count
df_2024.shape


# Inspect Column Headers
df_2024.columns


# Inspect Dataframe
df_2024.head()


# Inspect Dataframe for Null Values
df_2024.isna().sum()


# Create New Dataframe with Specific Headers - Renaming Columns
df_2024_new = df_2024[['Country name', 'Ladder score']]
df_2024_new = df_2024_new.rename(columns = {'Country name': 'Country', 'Ladder score': 'Happiness Score - 2024'})
df_2024_new.head()


# Merge DataFrames
merged_df = df_2012_new.merge(combined_df_2013, on='Country', how='outer').merge(df_2015_new, on='Country', how='outer')\
    .merge(df_2016_new, on='Country', how='outer').merge(df_2017_new, on='Country', how='outer')\
    .merge(df_2018_new, on='Country', how='outer').merge(df_2019_new, on='Country', how='outer')\
    .merge(df_2020_new, on='Country', how='outer').merge(df_2021_new, on='Country', how='outer')\
    .merge(df_2022_new, on='Country', how='outer').merge(df_2023_new, on='Country', how='outer')\
    .merge(df_2024_new, on='Country', how='outer')
merged_df


# Make a copy of the DataFrame for manipulation and clean up
merged_df_copy = merged_df.copy()


# Remove any rows beyond Zimbabwe
merged_df_copy = merged_df_copy.iloc[:222]
merged_df_copy


# Remove asterisks from the end of the words in the 'Country' column using Regex
merged_df_copy.iloc[:, 0] = merged_df_copy.iloc[:, 0].str.replace(r'\*$', '', regex=True)
merged_df_copy


# Find countries that use the '&' symbol
countries_with_ampersand = merged_df_copy[merged_df_copy['Country'].str.contains('&')]
countries_with_ampersand


# Using iloc to access the 'Country' column (index 0) and replace '&' with 'and'
merged_df_copy.iloc[:, 0] = merged_df_copy.iloc[:, 0].str.replace('&', 'and', regex=False)


# Find countries that use the word 'and'
countries_with_and = merged_df_copy[merged_df_copy['Country'].str.contains('and')]
countries_with_and


# Remove the row with NaN values and incomplete 'and' 
merged_df_copy = merged_df_copy.drop(index=23) # Bosnia and
merged_df_copy = merged_df_copy.drop(index=201) # Trinidad and

# Reset the index if needed
merged_df_copy.reset_index(drop=True, inplace=True)
#merged_df_copy


# Find countries that use a comma
countries_with_comma = merged_df_copy[merged_df_copy['Country'].str.contains(',')]
countries_with_comma


# Remove periods from the 'Country' column using regex
merged_df_copy['Country'] = merged_df_copy['Country'].str.replace(r'\.', '', regex=True)

# Find countries that use a comma
countries_with_comma = merged_df_copy[merged_df_copy['Country'].str.contains(',')]
countries_with_comma


# Find countries that use the word 'of'
countries_with_of = merged_df_copy[merged_df_copy['Country'].str.contains('of')]
countries_with_of


# Find countries that use the word 'Congo'
countries_with_Congo = merged_df_copy[merged_df_copy['Country'].str.contains('Congo')]
countries_with_Congo


# Rename 'Bosnia Herzegovina' to 'Bosnia and Herzegovina'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('Bosnia Herzegovina', 'Bosnia and Herzegovina')

# Rename 'Congo Brazzaville' to 'Congo [Republic]'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('Congo Brazzaville', 'Congo [Republic]')

# Rename 'Congo (Brazzaville)' to 'Congo [Republic]'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('Congo (Brazzaville)', 'Congo [Republic]')

# Rename 'Congo' to 'Congo [Republic]'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('Congo', 'Congo [Republic]')

# Rename '(Brazzaville)' to 'Congo [Republic]'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('(Brazzaville)', 'Congo [Republic]')

# Rename 'Congo (Kinshasa)' to 'Congo [DRC]'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('Congo (Kinshasa)', 'Congo [DRC]')

# Rename 'Congo Kinshasa' to 'Congo [DRC]'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('Congo Kinshasa', 'Congo [DRC]')

# Rename 'Dominican' to 'Dominican Republic'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('Dominican', 'Dominican Republic')

# Rename 'Hong Kong SAR, China' to 'Hong Kong'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('Hong Kong SAR, China', 'Hong Kong')

# Rename 'Hong Kong SAR of China' to 'Hong Kong'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('Hong Kong SAR of China', 'Hong Kong')

# Rename 'Palestine' to 'Palestinian Territories'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('Palestine', 'Palestinian Territories')

# Rename 'State of Palestine' to 'Palestinian Territories'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('State of Palestine', 'Palestinian Territories')

# Rename 'Somaliland' to 'Somalia'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('Somaliland', 'Somalia')

# Rename 'Somaliland region' to 'Somalia'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('Somaliland region', 'Somalia')

# Rename 'Taiwan Province of China' to 'Taiwan'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('Taiwan Province of China', 'Taiwan')

# Rename 'Eswatini, Kingdom of' to 'Swaziland'
merged_df_copy['Country'] = merged_df_copy['Country'].replace('Eswatini, Kingdom of', 'Swaziland')


# Finding Duplicates
duplicates = merged_df_copy[merged_df_copy.duplicated(subset=['Country'], keep=False)]
duplicates


# Convert the specified columns to numeric
columns_to_convert = ['Happiness Score - 2012', 'Happiness Score - 2013', 'Happiness Score - 2015', 
                      'Happiness Score - 2016', 'Happiness Score - 2017', 'Happiness Score - 2018', 
                      'Happiness Score - 2019', 'Happiness Score - 2020', 'Happiness Score - 2021', 
                      'Happiness Score - 2022', 'Happiness Score - 2023', 'Happiness Score - 2024']

merged_df_copy[columns_to_convert] = merged_df_copy[columns_to_convert].apply(pd.to_numeric, errors='coerce')

# Truncate values to 2 decimal places
merged_df_copy[columns_to_convert] = np.trunc(merged_df_copy[columns_to_convert] * 100) / 100

#merged_df_copy


# Merge rows where the country is duplicated by summing the happiness scores, including NaN values

# Replace NaN values with 0
merged_df_copy.fillna(0, inplace=True)

merged_df_copy = merged_df_copy.groupby('Country', as_index=False).agg({
    'Happiness Score - 2012': 'sum',
    'Happiness Score - 2013': 'sum',
    'Happiness Score - 2015': 'sum',
    'Happiness Score - 2016': 'sum',
    'Happiness Score - 2017': 'sum', 
    'Happiness Score - 2018': 'sum', 
    'Happiness Score - 2019': 'sum', 
    'Happiness Score - 2020': 'sum', 
    'Happiness Score - 2021': 'sum', 
    'Happiness Score - 2022': 'sum', 
    'Happiness Score - 2023': 'sum', 
    'Happiness Score - 2024': 'sum'
})

# Finding Duplicates
duplicates = merged_df_copy[merged_df_copy.duplicated(subset=['Country'], keep=False)]
duplicates


# Reset the index if needed
merged_df_copy.reset_index(drop=True, inplace=True)
merged_df_copy.head(15)


merged_df_copy.shape


# Create CSV File
merged_df_copy.to_csv('happiness_score.csv', index=False, header=True)





os.chdir('C:/Users/yiran/OneDrive/Documents/GitHub/project-3')

# Import Data from World Bank "Popular Indicators" Development Indicators full csv file
worldbank_data = Path("../project-3/data/worldbank.csv")

# Generate DataFrame
worldbank_df = pd.read_csv(worldbank_data, encoding="utf-8", low_memory=False)


# Inspect World Bank data shape
worldbank_df.shape


# Inspect column headers
worldbank_df.columns


# Inspect World Bank data
worldbank_df.head()


# Find null values
worldbank_df.isna().sum()


# Renaming Columns
worldbank_df_new = worldbank_df[['Series Name', 'Country Name', 'Country Code',
                                 '2000 [YR2000]', '2001 [YR2001]', '2002 [YR2002]',
                                 '2003 [YR2003]', '2004 [YR2004]', '2005 [YR2005]',
                                 '2006 [YR2006]', '2007 [YR2007]', '2008 [YR2008]',
                                 '2009 [YR2009]', '2010 [YR2010]', '2011 [YR2011]',
                                 '2012 [YR2012]', '2013 [YR2013]', '2014 [YR2014]', '2015 [YR2015]']]
worldbank_df_new = worldbank_df_new.rename(columns = {'Series Name': 'series', 'Country Name': 'country', 'Country Code': 'code',
                                            '2000 [YR2000]': 'yr2000', '2001 [YR2001]': 'yr2001', '2002 [YR2002]': 'yr2002',
                                            '2003 [YR2003]': 'yr2003', '2004 [YR2004]': 'yr2004', '2005 [YR2005]': 'yr2005',
                                            '2006 [YR2006]': 'yr2006', '2007 [YR2007]': 'yr2007', '2008 [YR2008]': 'yr2008',
                                            '2009 [YR2009]': 'yr2009', '2010 [YR2010]': 'yr2010', '2011 [YR2011]': 'yr2011',
                                            '2012 [YR2012]': 'yr2012', '2013 [YR2013]': 'yr2013', '2014 [YR2014]': 'yr2014',
                                            '2015 [YR2015]': 'yr2015'})
worldbank_df_new.head()


# Use regex to replace ".." with "0"

# Replace ".." with "0" using regex
worldbank_df_new['yr2000'] = worldbank_df_new['yr2000'].str.replace(r'\.\.', '0', regex=True)



# Check that regex operation was successful
worldbank_df_new['yr2000']


# Replace the rest of ".." instances with "0" in remaining columns
# Replace ".." with "0" in multiple columns
replace = ['yr2001', 'yr2002', 'yr2003', 'yr2004', 'yr2005', 'yr2006', 'yr2007', 'yr2008',
                      'yr2009', 'yr2010', 'yr2011', 'yr2012', 'yr2013', 'yr2014', 'yr2015']
worldbank_df_new[replace] = worldbank_df_new[replace].replace(r'\.\.', '0', regex=True)



# Check that regex operation was successful
worldbank_df_new





# Select rows based on text match in the second column (e.g., where column2 contains 'berry')
energy_use = worldbank_df_new[worldbank_df_new['series'].str.contains('Energy use', na=False)]
gdp_percap = worldbank_df_new[worldbank_df_new['series'].str.contains('GDP per capita', na=False)]
mobile = worldbank_df_new[worldbank_df_new['series'].str.contains('Mobile cellular subscriptions', na=False)]



# Check row selection
energy_use


# Convert to csv files
energy_use.to_csv('energy_use.csv', index=False, header=True)
gdp_percap.to_csv('gdp_percap.csv', index=False, header=True)
mobile.to_csv('mobile.csv', index=False, header=True)

















# Create SQLite Database for happiness scores 2012-2024

from sqlalchemy import create_engine, Column, Integer, String, Float, Text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import Session
Base = declarative_base()


# Define happiness_score table
class Happiness(Base):
    __tablename__ = "happiness_score"
    country = Column(String, primary_key=True)
    hs2012 = Column(Float)
    hs2013 = Column(Float)
    hs2015 = Column(Float)
    hs2016 = Column(Float)
    hs2017 = Column(Float)
    hs2018 = Column(Float)
    hs2019 = Column(Float)
    hs2020 = Column(Float)
    hs2021 = Column(Float)
    hs2022 = Column(Float)
    hs2023 = Column(Float)
    hs2024 = Column(Float)
    


# Create table in SQLite database
Base.metadata.tables


# Create database engine
engine = create_engine("sqlite:///../db/data.sqlite")


# Check table creation in database
Base.metadata.create_all(engine)


# Begin session
session = Session(engine)


# Add happiness data to open session
for i in merged_df_copy.index:
    session.add(Happiness(
        country = merged_df_copy["Country"][i],
        hs2012 = merged_df_copy["Happiness Score - 2012"][i],
        hs2013 = merged_df_copy["Happiness Score - 2013"][i],
        hs2015 = merged_df_copy["Happiness Score - 2015"][i],
        hs2016 = merged_df_copy["Happiness Score - 2016"][i],
        hs2017 = merged_df_copy["Happiness Score - 2017"][i],
        hs2018 = merged_df_copy["Happiness Score - 2018"][i],
        hs2019 = merged_df_copy["Happiness Score - 2019"][i],
        hs2020 = merged_df_copy["Happiness Score - 2020"][i],
        hs2021 = merged_df_copy["Happiness Score - 2021"][i],
        hs2022 = merged_df_copy["Happiness Score - 2022"][i],
        hs2023 = merged_df_copy["Happiness Score - 2023"][i],
        hs2024 = merged_df_copy["Happiness Score - 2024"][i],
    )


# Add happiness data to database
engine.execute("SELECT * FROM Happiness").fetchall()


# Check data going into database
session.new


# Commit data to database
session.commit()


# Check committed data
session.query(Happiness.country, Happiness.hs2012, Happiness.hs2024).all()





# rinse and repeat SQLite process


# Join on country name












